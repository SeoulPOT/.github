# DATA
<details>
  <summary><h2>📂 데이터 수집</h2></summary>

### <mark>💾 기존 크롤링 방법</mark>

> csv 파일을 읽어 네이버 페이지 접속함
> 
> 필요한 컬럼에 맞는 내용을 selenium, beatufulsoup을 이용하여 크롤링함
>
> 리뷰 양이 많은 가게일수록 '더보기' 클릭에 상당한 시간 소요 **(가게 당 기본 1시간)**
>
> 리뷰 데이터가 많은 (4,000개 이상) 가게를 크롤링하는데 무리가 있다고 판당 -> 적재할 데이터를 줄여야하는 문제 발생함

<br/>

### <mark>💾 변경한 크롤링 방법</mark>
> **Graphql** 사용
> 
> 클라이언트가 Graphql 쿼리를 서버에 전송하면, 서버는 해당 쿼리를 해석하여 요청된 데이터만 반환함
>
> ex) 리뷰 데이터의 내용과 사진을 요청하면, 그에 맞는 데이터만 응답함
>
> 크롤링 시간 대폭 축소 (13만개 공간 데이터 수집 소요 시간 : **3일**)

<br/>

### <mark>🎯 5개구 선정 이유</mark>

**① 종로구 중구 강남구 용산구**

> 서울시 주요 관광지 입장객 통계를 통해 다른 구에 비해 상당히 많은 관광객이 방문한 것을 확인함
>
> <img width="983" alt="스크린샷 2024-09-29 오후 7 01 53" src="https://github.com/user-attachments/assets/a2fc0d60-514f-4e96-95ab-8a3178d4fa91">

</br>

**② 마포구 추가 선정 이유**

> **레드로드**(관광특화의 거리) 조성 전 외국인 방문객 수가 3만명대였으나 조성 후 13만명으로 4배이상 증가한 것을 확인 후 추가 선정함
> 
> <img width="863" alt="스크린샷 2024-09-29 오후 7 32 08" src="https://github.com/user-attachments/assets/171fb121-7043-4ac9-b97b-b8c337d329c8"> 


<br/>
</details>
<details>
  <summary><h2>📑 데이터 전처리</summary>

<details>
  
  <summary><h3> 🏠 가게 전처리 </h3></summary>

### <mark>🎯 목적</mark>

> 데이터 적재에 필요하지 않은 내용 제거 & 모델 학습시 필요한 데이터만 추합하기 위함


<br/>

## <mark>💾 주요 작업 항목</mark>

### <mark>📃 과정</mark>

**① 리뷰 정보 전처리**

> **필요한 정보 :**
> 실 방문자 리뷰 수만 추출하고자 함
>
>
> **❓ 실 방문자 수만 추출한 이유**
>
> **별점 :** 
> 2021.10.26 일자로 별점을 평가하는 기능이 종료되어 이후 생긴 가게에 대한 별점 정보가 존재하지 않기에 제거함
>
> **블로그 리뷰 수 :** 
> 서울팟은 실 방문자 리뷰를 바탕으로 광고성 필터링 및 긍부정 감정분석한 정보를 사용자에게 제공하기에 필요하지 않은 정보라 판별함
>
> </br>
> 리뷰 정보 형태 파악
>
> - 별점\n4.35방문자 리뷰 1,283블로그 리뷰 471
> - 별점\n4.52방문자 리뷰 236블로그 리뷰 2,293\n추석연휴 무료 개방\n안내
></br>
> 방문자 리뷰 수만 추출
>
> - 1283 / 236
>
> 
**② 가게 영업시간 전처리**

> **필요한 정보 :**
> 현 영업 상태(운영 종료, 영업 중 등), 요일별 영업 정보, 특정 공휴일 등을 제거한 주요 영업시간 및 정기휴무 
>
> </br>
> 영업시간 형태 파악
>
> - 운영 종료\n11:00에 운영 시작\n11시 0분에 운영 시작\n토\n11:00
> - 운영 종료\n내일 휴무\n내일 휴무\n토\n12:00 - 18:30\n일\n정기휴무
> 
></br>
> 정기적인 영업시간 추출
>
> - 12:00 - 18:30 / 09:00 - 21:00
>
</br>
</details>


<details>
  <summary><h3>📑 리뷰 전처리</h3></summary>

  
**① 리뷰에 포함된 태그 종류 파악**

> - "'v_acquaintance' : '지인·동료'"
> - "'v_business' : '비즈니스'"
> - "'v_casual_outing' : '나들이'"
</br>

**② 2차 태그 필터링**

> 필요한 태그
>
```python
valid_tags = {
    '친구', '지인·동료', '혼자', '연인·배우자', '아이', '부모님',
    '형제', '친척·형제', '반려동물', '기타', '친목', '일상', 
    '데이트', '가족모임', '회식', '기념일', '여행', '나들이', '비즈니스'
}
```
> 
> - 필요하지 않은 태그 및 사용할 태그의 영어 제거
> - 'v_for_pickup'
>
> - 필요한 태그 한글 정보만 추출
> - '친구', '지인·동료'
</br>

**③ 3차 태그 필터링**

> 태그 구분 기준
> - 네이버 지도 리뷰에 구분되어 있는 것을 토대로 기준을 잡음
> - with_tag / daily_tag
```python
daily_tags = {'데이트', '친목', '나들이', '여행', '일상', '기념일', '회식', '가족모임', '비즈니스'}
with_tags = {'연인·배우자', '친구', '지인·동료', '혼자', '아이', '부모님', '반려동물', '친척·형제', '기타'}
```
</br>

**④ 리뷰 작성 날짜 전처리**

> 리뷰 작성 날짜 통일
> ex) 09.24 -> 년도가 없는 경우 / 23.09.26 -> 년도가 있는 경우
>
> 년-월-일 형태로 전처리 함으로써 모든 리뷰 날짜 통일
> - 2024-08-28
<br/>
</details>
</details>

<details>  
  <summary><h2>💻 데이터 적재</summary>


**📑 적재시킬 데이터** (리뷰 데이터 라벨링 & 공간 데이터 라벨링 후)

> 긍부정 & 최신순 10개
>
> 감정점수 높은 순 -> 0.9 이상 / 최대 10개
> 
> 감정점수 낮은 순 -> 0.1 이하 / 최대 10개
> 
> 글자 수 20자 이상인 리뷰


<br/>

**❓ 적재시킬 데이터 선택 기준**

> 리뷰 1,000개 시각화해도 사용자가 전체 리뷰를 확인하지 않을 것으로 예상함
>
> DB가 무거워지는 문제점 발생함
> - 대시보드에서 평판을 전반적으로 파악 후 가장 유용한 10개의 리뷰를 시각화
>
> 신뢰성 있는 정보를 얻기 위해 20자 이상의 리뷰만 적재

<br/>

**🗂️ 사용한 DB**

> Maria DB

<br/>



</details>

